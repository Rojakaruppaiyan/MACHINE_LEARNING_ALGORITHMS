{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0bff242-290e-45c7-a529-335fc4bb7f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Evaluating WITHOUT Augmentation\n",
      "🎯 Accuracy: 83.99%\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cipher       0.82      0.88      0.85       296\n",
      "        hash       0.88      0.91      0.89       306\n",
      "         hnv       0.82      0.90      0.86       306\n",
      "       hnvor       0.96      0.59      0.73        39\n",
      "          iv       0.86      0.73      0.79       107\n",
      "         key       0.85      0.65      0.74       110\n",
      "          tm       0.81      0.83      0.82       262\n",
      "         tls       0.87      0.80      0.84       142\n",
      "\n",
      "    accuracy                           0.84      1568\n",
      "   macro avg       0.86      0.79      0.81      1568\n",
      "weighted avg       0.84      0.84      0.84      1568\n",
      "\n",
      "📉 Confusion Matrix:\n",
      "[[260   3  15   0   3   3  10   2]\n",
      " [  5 277  10   0   4   0   7   3]\n",
      " [  6  12 275   0   1   1   9   2]\n",
      " [  4   1   4  23   0   0   6   1]\n",
      " [ 10   5   4   0  78   6   4   0]\n",
      " [ 15   7   8   0   4  72   4   0]\n",
      " [ 11   9  14   0   1   0 218   9]\n",
      " [  7   2   4   1   0   3  11 114]]\n",
      "\n",
      "🧪 Evaluating WITH Augmentation\n",
      "🎯 Accuracy: 82.08%\n",
      "\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cipher       0.78      0.85      0.81       296\n",
      "        hash       0.81      0.89      0.85       306\n",
      "         hnv       0.84      0.87      0.85       306\n",
      "       hnvor       0.74      0.59      0.66        39\n",
      "          iv       0.90      0.78      0.83       107\n",
      "         key       0.79      0.67      0.73       110\n",
      "          tm       0.85      0.79      0.82       262\n",
      "         tls       0.84      0.76      0.80       142\n",
      "\n",
      "    accuracy                           0.82      1568\n",
      "   macro avg       0.82      0.78      0.79      1568\n",
      "weighted avg       0.82      0.82      0.82      1568\n",
      "\n",
      "📉 Confusion Matrix:\n",
      "[[253  14  11   2   2   6   7   1]\n",
      " [ 11 272  11   0   2   1   4   5]\n",
      " [ 13  12 267   1   0   2   8   3]\n",
      " [  5   2   3  23   2   0   2   2]\n",
      " [  7   5   2   0  83   5   5   0]\n",
      " [ 15   8   6   3   2  74   2   0]\n",
      " [ 12  15  13   1   1   3 207  10]\n",
      " [  9   7   6   1   0   3   8 108]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# === Load Dataset ===\n",
    "df = pd.read_csv(\"bog_features1.csv\") \n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# === Label Mapping (adjust as per your label encoding) ===\n",
    "label_mapping = {\n",
    "    0: 'cipher',\n",
    "    1: 'hash',\n",
    "    2: 'hnv',\n",
    "    3: 'hnvor',\n",
    "    4: 'iv',\n",
    "    5: 'key',\n",
    "    6: 'tm',\n",
    "    7: 'tls'\n",
    "}\n",
    "\n",
    "# === Split Data ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Evaluation Function ===\n",
    "def evaluate_model(model_path, scaler_path, model_name):\n",
    "    print(f\"\\n🧪 Evaluating {model_name}\")\n",
    "\n",
    "    # Load model and scaler\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    # Scale test data\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # === Metrics ===\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"🎯 Accuracy: {round(acc * 100, 2)}%\")\n",
    "\n",
    "    print(\"\\n📋 Classification Report:\")\n",
    "    print(classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=[label_mapping[i] for i in sorted(label_mapping.keys())]\n",
    "    ))\n",
    "\n",
    "    print(\"📉 Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# === Evaluate Models ===\n",
    "evaluate_model(\"svm_best_model.pkl\", \"scaler.pkl\", \"WITHOUT Augmentation\")\n",
    "evaluate_model(\"svm_aug_better_model.pkl\", \"scaler_aug_better.pkl\", \"WITH Augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2da543-d98b-46d5-bb21-f18f5cff6a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.36315357\n",
      "Validation score: 0.654459\n",
      "Iteration 2, loss = 0.89120268\n",
      "Validation score: 0.707006\n",
      "Iteration 3, loss = 0.76170528\n",
      "Validation score: 0.754777\n",
      "Iteration 4, loss = 0.67753921\n",
      "Validation score: 0.778662\n",
      "Iteration 5, loss = 0.62613402\n",
      "Validation score: 0.778662\n",
      "Iteration 6, loss = 0.58692074\n",
      "Validation score: 0.791401\n",
      "Iteration 7, loss = 0.56083536\n",
      "Validation score: 0.805732\n",
      "Iteration 8, loss = 0.56601344\n",
      "Validation score: 0.800955\n",
      "Iteration 9, loss = 0.50834024\n",
      "Validation score: 0.826433\n",
      "Iteration 10, loss = 0.47758281\n",
      "Validation score: 0.818471\n",
      "Iteration 11, loss = 0.46350987\n",
      "Validation score: 0.826433\n",
      "Iteration 12, loss = 0.43914921\n",
      "Validation score: 0.831210\n",
      "Iteration 13, loss = 0.43796174\n",
      "Validation score: 0.802548\n",
      "Iteration 14, loss = 0.41939134\n",
      "Validation score: 0.821656\n",
      "Iteration 15, loss = 0.40969092\n",
      "Validation score: 0.845541\n",
      "Iteration 16, loss = 0.38686609\n",
      "Validation score: 0.839172\n",
      "Iteration 17, loss = 0.36454212\n",
      "Validation score: 0.831210\n",
      "Iteration 18, loss = 0.36801898\n",
      "Validation score: 0.823248\n",
      "Iteration 19, loss = 0.36950161\n",
      "Validation score: 0.832803\n",
      "Iteration 20, loss = 0.38031488\n",
      "Validation score: 0.837580\n",
      "Iteration 21, loss = 0.32978558\n",
      "Validation score: 0.818471\n",
      "Iteration 22, loss = 0.32292804\n",
      "Validation score: 0.834395\n",
      "Iteration 23, loss = 0.31866016\n",
      "Validation score: 0.832803\n",
      "Iteration 24, loss = 0.29771635\n",
      "Validation score: 0.826433\n",
      "Iteration 25, loss = 0.27577098\n",
      "Validation score: 0.826433\n",
      "Iteration 26, loss = 0.26501383\n",
      "Validation score: 0.823248\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "✅ Model and scaler saved!\n",
      "🎯 Accuracy: 0.8042091836734694\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       296\n",
      "           1       0.89      0.85      0.87       306\n",
      "           2       0.78      0.88      0.83       306\n",
      "           3       0.83      0.51      0.63        39\n",
      "           4       0.67      0.73      0.70       107\n",
      "           5       0.79      0.59      0.68       110\n",
      "           6       0.82      0.78      0.80       262\n",
      "           7       0.79      0.81      0.80       142\n",
      "\n",
      "    accuracy                           0.80      1568\n",
      "   macro avg       0.80      0.75      0.77      1568\n",
      "weighted avg       0.81      0.80      0.80      1568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# 1. Load CSV\n",
    "df = pd.read_csv('bog_features1.csv', header=None)\n",
    "\n",
    "# 2. Remove invalid label rows (e.g. 'label' string)\n",
    "df = df[df.iloc[:, -1] != 'label']\n",
    "\n",
    "# 3. Separate features and labels\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# 4. Encode string labels (for consistency in later predictions)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "joblib.dump(le, \"label_encoder_no_aug.pkl\")  # Save label encoder\n",
    "\n",
    "# 5. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# 6. Feature scaling (important for MLP)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "joblib.dump(scaler, \"scaler_no_aug.pkl\")  # Save the scaler\n",
    "\n",
    "# 7. Define MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.001,\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 8. Train the model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# 9. Save the model\n",
    "joblib.dump(mlp, \"mlp_model_no_aug.pkl\")\n",
    "print(\"✅ Model and scaler saved!\")\n",
    "\n",
    "# 10. Evaluate the model\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(\"🎯 Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"📋 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299d62e6-1066-470f-b3b1-dedddad61331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.25324528\n",
      "Validation score: 0.685714\n",
      "Iteration 2, loss = 0.78948519\n",
      "Validation score: 0.710204\n",
      "Iteration 3, loss = 0.65606862\n",
      "Validation score: 0.780612\n",
      "Iteration 4, loss = 0.56839821\n",
      "Validation score: 0.780612\n",
      "Iteration 5, loss = 0.50759067\n",
      "Validation score: 0.818367\n",
      "Iteration 6, loss = 0.46517990\n",
      "Validation score: 0.825510\n",
      "Iteration 7, loss = 0.43604650\n",
      "Validation score: 0.835714\n",
      "Iteration 8, loss = 0.39509006\n",
      "Validation score: 0.843878\n",
      "Iteration 9, loss = 0.37196138\n",
      "Validation score: 0.848980\n",
      "Iteration 10, loss = 0.35283980\n",
      "Validation score: 0.839796\n",
      "Iteration 11, loss = 0.34027737\n",
      "Validation score: 0.852041\n",
      "Iteration 12, loss = 0.31021727\n",
      "Validation score: 0.860204\n",
      "Iteration 13, loss = 0.29655192\n",
      "Validation score: 0.859184\n",
      "Iteration 14, loss = 0.29119521\n",
      "Validation score: 0.862245\n",
      "Iteration 15, loss = 0.26516688\n",
      "Validation score: 0.868367\n",
      "Iteration 16, loss = 0.25297317\n",
      "Validation score: 0.881633\n",
      "Iteration 17, loss = 0.23592923\n",
      "Validation score: 0.887755\n",
      "Iteration 18, loss = 0.23171385\n",
      "Validation score: 0.880612\n",
      "Iteration 19, loss = 0.22417982\n",
      "Validation score: 0.866327\n",
      "Iteration 20, loss = 0.21833418\n",
      "Validation score: 0.881633\n",
      "Iteration 21, loss = 0.19953093\n",
      "Validation score: 0.879592\n",
      "Iteration 22, loss = 0.18223975\n",
      "Validation score: 0.878571\n",
      "Iteration 23, loss = 0.20441143\n",
      "Validation score: 0.891837\n",
      "Iteration 24, loss = 0.17364396\n",
      "Validation score: 0.890816\n",
      "Iteration 25, loss = 0.15835330\n",
      "Validation score: 0.892857\n",
      "Iteration 26, loss = 0.14137455\n",
      "Validation score: 0.890816\n",
      "Iteration 27, loss = 0.15672848\n",
      "Validation score: 0.882653\n",
      "Iteration 28, loss = 0.14875422\n",
      "Validation score: 0.890816\n",
      "Iteration 29, loss = 0.12723871\n",
      "Validation score: 0.886735\n",
      "Iteration 30, loss = 0.12503850\n",
      "Validation score: 0.891837\n",
      "Iteration 31, loss = 0.11583208\n",
      "Validation score: 0.881633\n",
      "Iteration 32, loss = 0.13287259\n",
      "Validation score: 0.885714\n",
      "Iteration 33, loss = 0.12259121\n",
      "Validation score: 0.890816\n",
      "Iteration 34, loss = 0.09140734\n",
      "Validation score: 0.900000\n",
      "Iteration 35, loss = 0.08847389\n",
      "Validation score: 0.893878\n",
      "Iteration 36, loss = 0.08471395\n",
      "Validation score: 0.895918\n",
      "Iteration 37, loss = 0.08000201\n",
      "Validation score: 0.891837\n",
      "Iteration 38, loss = 0.07688471\n",
      "Validation score: 0.885714\n",
      "Iteration 39, loss = 0.08806692\n",
      "Validation score: 0.893878\n",
      "Iteration 40, loss = 0.07300454\n",
      "Validation score: 0.901020\n",
      "Iteration 41, loss = 0.05669039\n",
      "Validation score: 0.900000\n",
      "Iteration 42, loss = 0.04891081\n",
      "Validation score: 0.906122\n",
      "Iteration 43, loss = 0.05577431\n",
      "Validation score: 0.894898\n",
      "Iteration 44, loss = 0.05915556\n",
      "Validation score: 0.890816\n",
      "Iteration 45, loss = 0.08863409\n",
      "Validation score: 0.898980\n",
      "Iteration 46, loss = 0.04968649\n",
      "Validation score: 0.900000\n",
      "Iteration 47, loss = 0.04698200\n",
      "Validation score: 0.903061\n",
      "Iteration 48, loss = 0.03479964\n",
      "Validation score: 0.906122\n",
      "Iteration 49, loss = 0.03186284\n",
      "Validation score: 0.902041\n",
      "Iteration 50, loss = 0.03104079\n",
      "Validation score: 0.900000\n",
      "Iteration 51, loss = 0.02999207\n",
      "Validation score: 0.898980\n",
      "Iteration 52, loss = 0.02289778\n",
      "Validation score: 0.904082\n",
      "Iteration 53, loss = 0.02671551\n",
      "Validation score: 0.896939\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "✅ SMOTE-augmented model and scaler saved!\n",
      "🎯 Accuracy: 0.8182397959183674\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       296\n",
      "           1       0.85      0.86      0.85       306\n",
      "           2       0.85      0.86      0.85       306\n",
      "           3       0.86      0.62      0.72        39\n",
      "           4       0.79      0.76      0.78       107\n",
      "           5       0.76      0.73      0.74       110\n",
      "           6       0.77      0.83      0.80       262\n",
      "           7       0.82      0.78      0.80       142\n",
      "\n",
      "    accuracy                           0.82      1568\n",
      "   macro avg       0.82      0.78      0.80      1568\n",
      "weighted avg       0.82      0.82      0.82      1568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1. Load CSV\n",
    "df = pd.read_csv('bog_features1.csv', header=None)\n",
    "\n",
    "# 2. Remove invalid label row (with literal string 'label')\n",
    "df = df[df.iloc[:, -1] != 'label']\n",
    "\n",
    "# 3. Separate features and labels\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# 4. Encode labels (so SMOTE works and it's consistent)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "joblib.dump(le, \"label_encoder_aug.pkl\")  # Save encoder\n",
    "\n",
    "# 5. Train-test split (before SMOTE)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# 6. Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "joblib.dump(scaler, \"scaler_aug.pkl\")  # Save the scaler\n",
    "\n",
    "# 7. Apply SMOTE to training data only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_aug, y_train_aug = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 8. Define MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.001,\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 9. Train the model\n",
    "mlp.fit(X_train_aug, y_train_aug)\n",
    "\n",
    "# 10. Save model\n",
    "joblib.dump(mlp, \"mlp_model_aug.pkl\")\n",
    "print(\"✅ SMOTE-augmented model and scaler saved!\")\n",
    "\n",
    "# 11. Evaluate the model\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(\"🎯 Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"📋 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7cecb10-3552-4414-9162-ccd29b05f460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Model: SVM WITH Augmentation\n",
      "🎯 Random Sample Index: 1538\n",
      "✅ True Label: tm (encoded: 6)\n",
      "🔍 Predicted Label: tm (encoded: 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Test Set Evaluation:\n",
      "🎯 Accuracy: 83.99%\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cipher       0.82      0.88      0.85       296\n",
      "        hash       0.88      0.91      0.89       306\n",
      "         hnv       0.82      0.90      0.86       306\n",
      "       hnvor       0.96      0.59      0.73        39\n",
      "          iv       0.86      0.73      0.79       107\n",
      "         key       0.85      0.65      0.74       110\n",
      "          tm       0.81      0.83      0.82       262\n",
      "         tls       0.87      0.80      0.84       142\n",
      "\n",
      "    accuracy                           0.84      1568\n",
      "   macro avg       0.86      0.79      0.81      1568\n",
      "weighted avg       0.84      0.84      0.84      1568\n",
      "\n",
      "📉 Confusion Matrix:\n",
      "[[260   3  15   0   3   3  10   2]\n",
      " [  5 277  10   0   4   0   7   3]\n",
      " [  6  12 275   0   1   1   9   2]\n",
      " [  4   1   4  23   0   0   6   1]\n",
      " [ 10   5   4   0  78   6   4   0]\n",
      " [ 15   7   8   0   4  72   4   0]\n",
      " [ 11   9  14   0   1   0 218   9]\n",
      " [  7   2   4   1   0   3  11 114]]\n",
      "\n",
      "🔎 Model: SVM WITHOUT Augmentation\n",
      "🎯 Random Sample Index: 1510\n",
      "✅ True Label: tls (encoded: 7)\n",
      "🔍 Predicted Label: tls (encoded: 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Test Set Evaluation:\n",
      "🎯 Accuracy: 82.08%\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cipher       0.78      0.85      0.81       296\n",
      "        hash       0.81      0.89      0.85       306\n",
      "         hnv       0.84      0.87      0.85       306\n",
      "       hnvor       0.74      0.59      0.66        39\n",
      "          iv       0.90      0.78      0.83       107\n",
      "         key       0.79      0.67      0.73       110\n",
      "          tm       0.85      0.79      0.82       262\n",
      "         tls       0.84      0.76      0.80       142\n",
      "\n",
      "    accuracy                           0.82      1568\n",
      "   macro avg       0.82      0.78      0.79      1568\n",
      "weighted avg       0.82      0.82      0.82      1568\n",
      "\n",
      "📉 Confusion Matrix:\n",
      "[[253  14  11   2   2   6   7   1]\n",
      " [ 11 272  11   0   2   1   4   5]\n",
      " [ 13  12 267   1   0   2   8   3]\n",
      " [  5   2   3  23   2   0   2   2]\n",
      " [  7   5   2   0  83   5   5   0]\n",
      " [ 15   8   6   3   2  74   2   0]\n",
      " [ 12  15  13   1   1   3 207  10]\n",
      " [  9   7   6   1   0   3   8 108]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# === Label Mapping ===\n",
    "label_mapping = {\n",
    "    0: 'cipher',\n",
    "    1: 'hash',\n",
    "    2: 'hnv',\n",
    "    3: 'hnvor',\n",
    "    4: 'iv',\n",
    "    5: 'key',\n",
    "    6: 'tm',\n",
    "    7: 'tls'\n",
    "}\n",
    "\n",
    "# === Load and split dataset ===\n",
    "df = pd.read_csv(\"bog_features1.csv\")\n",
    "X = df.drop(columns=[\"label\"]).astype(float)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# No encoding needed; labels already numeric\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Generalized evaluation function for SVM ===\n",
    "def evaluate_and_predict(model_path, scaler_path, model_name):\n",
    "    print(f\"\\n🔎 Model: {model_name}\")\n",
    "\n",
    "    # Load model and scaler\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    # === Random sample prediction ===\n",
    "    random_idx = random.randint(0, len(X_test) - 1)\n",
    "    input_vector = X_test.iloc[random_idx].values.reshape(1, -1)\n",
    "    true_label_encoded = y_test.iloc[random_idx]\n",
    "    true_label_name = label_mapping[int(true_label_encoded)]\n",
    "\n",
    "    input_scaled = scaler.transform(input_vector)\n",
    "    pred_encoded = model.predict(input_scaled)[0]\n",
    "    pred_label_name = label_mapping[int(pred_encoded)]\n",
    "\n",
    "    print(f\"🎯 Random Sample Index: {random_idx}\")\n",
    "    print(f\"✅ True Label: {true_label_name} (encoded: {true_label_encoded})\")\n",
    "    print(f\"🔍 Predicted Label: {pred_label_name} (encoded: {pred_encoded})\")\n",
    "\n",
    "    # === Full test set evaluation ===\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    print(\"\\n📊 Test Set Evaluation:\")\n",
    "    print(f\"🎯 Accuracy: {round(accuracy_score(y_test, y_pred) * 100, 2)}%\")\n",
    "    print(\"📋 Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[label_mapping[i] for i in sorted(label_mapping)]))\n",
    "    print(\"📉 Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# === Run for both models ===\n",
    "evaluate_and_predict(\"svm_best_model.pkl\", \"scaler.pkl\", \"SVM WITH Augmentation\")\n",
    "evaluate_and_predict(\"svm_aug_better_model.pkl\", \"scaler_aug_better.pkl\", \"SVM WITHOUT Augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa9269b6-3f02-49fa-85bc-f0122716e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Model: MLP WITHOUT Augmentation\n",
      "🎯 Random Sample Index: 404\n",
      "✅ True Label: 0 (encoded: 0)\n",
      "🔍 Predicted Label: 0 (encoded: 0)\n",
      "\n",
      "📊 Test Set Evaluation:\n",
      "🎯 Accuracy: 80.42%\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       296\n",
      "           1       0.89      0.85      0.87       306\n",
      "           2       0.78      0.88      0.83       306\n",
      "           3       0.83      0.51      0.63        39\n",
      "           4       0.67      0.73      0.70       107\n",
      "           5       0.79      0.59      0.68       110\n",
      "           6       0.82      0.78      0.80       262\n",
      "           7       0.79      0.81      0.80       142\n",
      "\n",
      "    accuracy                           0.80      1568\n",
      "   macro avg       0.80      0.75      0.77      1568\n",
      "weighted avg       0.81      0.80      0.80      1568\n",
      "\n",
      "📉 Confusion Matrix:\n",
      "[[250   6  19   0  12   2   5   2]\n",
      " [  7 261  14   1   8   2   6   7]\n",
      " [  9   8 268   1   4   2  11   3]\n",
      " [  3   1   3  20   4   2   5   1]\n",
      " [ 13   2   4   0  78   6   4   0]\n",
      " [ 18   4  11   0   7  65   1   4]\n",
      " [ 10  10  20   1   4   0 204  13]\n",
      " [  7   1   3   1   0   3  12 115]]\n",
      "\n",
      "🔎 Model: MLP WITH Augmentation\n",
      "🎯 Random Sample Index: 38\n",
      "✅ True Label: 0 (encoded: 0)\n",
      "🔍 Predicted Label: 0 (encoded: 0)\n",
      "\n",
      "📊 Test Set Evaluation:\n",
      "🎯 Accuracy: 81.82%\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       296\n",
      "           1       0.85      0.86      0.85       306\n",
      "           2       0.85      0.86      0.85       306\n",
      "           3       0.86      0.62      0.72        39\n",
      "           4       0.79      0.76      0.78       107\n",
      "           5       0.76      0.73      0.74       110\n",
      "           6       0.77      0.83      0.80       262\n",
      "           7       0.82      0.78      0.80       142\n",
      "\n",
      "    accuracy                           0.82      1568\n",
      "   macro avg       0.82      0.78      0.80      1568\n",
      "weighted avg       0.82      0.82      0.82      1568\n",
      "\n",
      "📉 Confusion Matrix:\n",
      "[[245  10  13   1   7   5  14   1]\n",
      " [ 10 262  12   1   3   5   8   5]\n",
      " [  8  14 262   1   3   4  11   3]\n",
      " [  4   2   1  24   2   1   4   1]\n",
      " [  9   2   4   0  81   5   6   0]\n",
      " [ 12   2   4   1   2  80   8   1]\n",
      " [  5  10  10   0   3   3 218  13]\n",
      " [  5   6   3   0   1   2  14 111]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# === Label Mapping (for display only) ===\n",
    "label_mapping = {\n",
    "    0: 'cipher',\n",
    "    1: 'hash',\n",
    "    2: 'hnv',\n",
    "    3: 'hnvor',\n",
    "    4: 'iv',\n",
    "    5: 'key',\n",
    "    6: 'tm',\n",
    "    7: 'tls'\n",
    "}\n",
    "\n",
    "# === Load and preprocess dataset ===\n",
    "df = pd.read_csv(\"bog_features1.csv\", header=None)\n",
    "df = df[df.iloc[:, -1] != 'label']\n",
    "X = df.iloc[:, :-1].astype(float).values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Load label encoder\n",
    "label_encoder = joblib.load(\"label_encoder_aug.pkl\")  # assuming both encoders have same mapping\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, stratify=y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Generalized evaluation function for MLP ===\n",
    "def evaluate_mlp(model_path, scaler_path, encoder_path, model_name):\n",
    "    print(f\"\\n🔎 Model: {model_name}\")\n",
    "\n",
    "    # Load model, scaler, encoder\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    encoder = joblib.load(encoder_path)\n",
    "\n",
    "    # === Random sample selection ===\n",
    "    random_idx = random.randint(0, len(X_test) - 1)\n",
    "    input_vector = X_test[random_idx].reshape(1, -1)\n",
    "    true_label_encoded = y_test[random_idx]\n",
    "    true_label_name = encoder.inverse_transform([true_label_encoded])[0]\n",
    "\n",
    "    # Prediction\n",
    "    input_scaled = scaler.transform(input_vector)\n",
    "    pred_encoded = model.predict(input_scaled)[0]\n",
    "    pred_label_name = encoder.inverse_transform([pred_encoded])[0]\n",
    "\n",
    "    print(f\"🎯 Random Sample Index: {random_idx}\")\n",
    "    print(f\"✅ True Label: {true_label_name} (encoded: {true_label_encoded})\")\n",
    "    print(f\"🔍 Predicted Label: {pred_label_name} (encoded: {pred_encoded})\")\n",
    "\n",
    "    # === Evaluation on test set ===\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    print(\"\\n📊 Test Set Evaluation:\")\n",
    "    print(f\"🎯 Accuracy: {round(accuracy_score(y_test, y_pred) * 100, 2)}%\")\n",
    "    print(\"📋 Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n",
    "    print(\"📉 Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# === Run for both models ===\n",
    "evaluate_mlp(\"mlp_model_no_aug.pkl\", \"scaler_no_aug.pkl\", \"label_encoder_no_aug.pkl\", \"MLP WITHOUT Augmentation\")\n",
    "evaluate_mlp(\"mlp_model_aug.pkl\", \"scaler_aug.pkl\", \"label_encoder_aug.pkl\", \"MLP WITH Augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "058200f5-0b16-465c-beb0-c9a6c92309e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Model: MLP WITHOUT Augmentation\n",
      "🎯 Random Sample Index: 1227\n",
      "✅ True Label: 7 (encoded: 7)\n",
      "🔍 Predicted Label: 7 (encoded: 7)\n",
      "\n",
      "📊 Test Set Evaluation:\n",
      "🎯 Accuracy: 80.42%\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       296\n",
      "           1       0.89      0.85      0.87       306\n",
      "           2       0.78      0.88      0.83       306\n",
      "           3       0.83      0.51      0.63        39\n",
      "           4       0.67      0.73      0.70       107\n",
      "           5       0.79      0.59      0.68       110\n",
      "           6       0.82      0.78      0.80       262\n",
      "           7       0.79      0.81      0.80       142\n",
      "\n",
      "    accuracy                           0.80      1568\n",
      "   macro avg       0.80      0.75      0.77      1568\n",
      "weighted avg       0.81      0.80      0.80      1568\n",
      "\n",
      "📉 Confusion Matrix:\n",
      "[[250   6  19   0  12   2   5   2]\n",
      " [  7 261  14   1   8   2   6   7]\n",
      " [  9   8 268   1   4   2  11   3]\n",
      " [  3   1   3  20   4   2   5   1]\n",
      " [ 13   2   4   0  78   6   4   0]\n",
      " [ 18   4  11   0   7  65   1   4]\n",
      " [ 10  10  20   1   4   0 204  13]\n",
      " [  7   1   3   1   0   3  12 115]]\n",
      "\n",
      "🔎 Model: MLP WITH Augmentation\n",
      "🎯 Random Sample Index: 626\n",
      "✅ True Label: 4 (encoded: 4)\n",
      "🔍 Predicted Label: 4 (encoded: 4)\n",
      "\n",
      "📊 Test Set Evaluation:\n",
      "🎯 Accuracy: 81.82%\n",
      "📋 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       296\n",
      "           1       0.85      0.86      0.85       306\n",
      "           2       0.85      0.86      0.85       306\n",
      "           3       0.86      0.62      0.72        39\n",
      "           4       0.79      0.76      0.78       107\n",
      "           5       0.76      0.73      0.74       110\n",
      "           6       0.77      0.83      0.80       262\n",
      "           7       0.82      0.78      0.80       142\n",
      "\n",
      "    accuracy                           0.82      1568\n",
      "   macro avg       0.82      0.78      0.80      1568\n",
      "weighted avg       0.82      0.82      0.82      1568\n",
      "\n",
      "📉 Confusion Matrix:\n",
      "[[245  10  13   1   7   5  14   1]\n",
      " [ 10 262  12   1   3   5   8   5]\n",
      " [  8  14 262   1   3   4  11   3]\n",
      " [  4   2   1  24   2   1   4   1]\n",
      " [  9   2   4   0  81   5   6   0]\n",
      " [ 12   2   4   1   2  80   8   1]\n",
      " [  5  10  10   0   3   3 218  13]\n",
      " [  5   6   3   0   1   2  14 111]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# === Label Mapping (for display only) ===\n",
    "label_mapping = {\n",
    "    0: 'cipher',\n",
    "    1: 'hash',\n",
    "    2: 'hnv',\n",
    "    3: 'hnvor',\n",
    "    4: 'iv',\n",
    "    5: 'key',\n",
    "    6: 'tm',\n",
    "    7: 'tls'\n",
    "}\n",
    "\n",
    "# === Load and preprocess dataset ===\n",
    "df = pd.read_csv(\"bog_features1.csv\", header=None)\n",
    "df = df[df.iloc[:, -1] != 'label']\n",
    "X = df.iloc[:, :-1].astype(float).values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Load label encoder\n",
    "label_encoder = joblib.load(\"label_encoder_aug.pkl\")  # assuming both encoders have same mapping\n",
    "y_encoded = label_encoder.transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, stratify=y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Generalized evaluation function for MLP ===\n",
    "def evaluate_mlp(model_path, scaler_path, encoder_path, model_name):\n",
    "    print(f\"\\n🔎 Model: {model_name}\")\n",
    "\n",
    "    # Load model, scaler, encoder\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    encoder = joblib.load(encoder_path)\n",
    "\n",
    "    # === Random sample selection ===\n",
    "    random_idx = random.randint(0, len(X_test) - 1)\n",
    "    input_vector = X_test[random_idx].reshape(1, -1)\n",
    "    true_label_encoded = y_test[random_idx]\n",
    "    true_label_name = encoder.inverse_transform([true_label_encoded])[0]\n",
    "\n",
    "    # Prediction\n",
    "    input_scaled = scaler.transform(input_vector)\n",
    "    pred_encoded = model.predict(input_scaled)[0]\n",
    "    pred_label_name = encoder.inverse_transform([pred_encoded])[0]\n",
    "\n",
    "    print(f\"🎯 Random Sample Index: {random_idx}\")\n",
    "    print(f\"✅ True Label: {true_label_name} (encoded: {true_label_encoded})\")\n",
    "    print(f\"🔍 Predicted Label: {pred_label_name} (encoded: {pred_encoded})\")\n",
    "\n",
    "    # === Evaluation on test set ===\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    print(\"\\n📊 Test Set Evaluation:\")\n",
    "    print(f\"🎯 Accuracy: {round(accuracy_score(y_test, y_pred) * 100, 2)}%\")\n",
    "    print(\"📋 Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n",
    "    print(\"📉 Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# === Run for both models ===\n",
    "evaluate_mlp(\"mlp_model_no_aug.pkl\", \"scaler_no_aug.pkl\", \"label_encoder_no_aug.pkl\", \"MLP WITHOUT Augmentation\")\n",
    "evaluate_mlp(\"mlp_model_aug.pkl\", \"scaler_aug.pkl\", \"label_encoder_aug.pkl\", \"MLP WITH Augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb59c6d-4d08-46db-8a00-c7905eaf2f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
